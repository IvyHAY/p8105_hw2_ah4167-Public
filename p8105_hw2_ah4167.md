p8105_hw2_ah4167
================
Aiying Huang
2023-09-26

# problem 1

``` r
options(scipen=999)
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

### First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

``` r
pols_month_df=
  read.csv("./data/fivethirtyeight_datasets/pols-month.csv")|>
  separate(
           col="mon",
           into=c("year","month","day"),
           sep="-")|>
  mutate(
    month=case_match(
      month,
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec")
  )|>
  mutate(
    president=case_match(
      prez_gop,
    0~"dem",
    1~"gop",
    2~"gop"
    )
  )|>
  mutate(year,year=as.numeric(year))|>
  select(-starts_with("prez_"))|>
  select(-day)
```

### Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

``` r
snp_df_1=
  read.csv("./data/fivethirtyeight_datasets/snp.csv")|>
  head(175)|>
  separate(
           col="date",
           into=c("year","month","day"),
           sep="/")|>
  mutate(
    year=case_match(
      year,
      "1"~2001,
    "2"~2002,
    "3"~2003,
    "4"~2004,
    "5"~2005,
    "6"~2006,
    "7"~2007,
    "8"~2008,
    "9"~2009,
    "10"~2010,
    "11"~2011,
    "12"~2012
    ),
    month=case_match(
      month,
    "1"~"Jan",
    "2"~"Feb",
    "3"~"Mar",
    "4"~"Apr",
    "5"~"May",
    "6"~"Jun",
    "7"~"Jul",
    "8"~"Aug",
    "9"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec")
  )|>
  select(-day)
```

``` r
snp_df_2=
  read.csv("./data/fivethirtyeight_datasets/snp.csv",skip=175)|>
  separate(
           col="X1.2.01",
           into=c("month","day","year"),
           sep="/")|>
  mutate(
    year=1900+as.numeric(year),
    month=case_match(
      month,
    "1"~"Jan",
    "2"~"Feb",
    "3"~"Mar",
    "4"~"Apr",
    "5"~"May",
    "6"~"Jun",
    "7"~"Jul",
    "8"~"Aug",
    "9"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec")
  )|>
  mutate(
    year=replace(year,year==1900,2000)
  )|>
  select(-day)|>
  rename(close=X1366.01001)
```

``` r
snp_df=
  bind_rows(snp_df_1,snp_df_2)|>
  arrange(year,month)
```

### Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

``` r
unemployment_df=
  read.csv("./data/fivethirtyeight_datasets/unemployment.csv")|>
  pivot_longer(
    Jan:Dec,
    names_to="month",
    values_to="unemployment"
  )|>
  janitor::clean_names()
```

### Join the datasets by merging snp into pols, and merging unemployment into the result.

``` r
Joint_df=
  left_join(pols_month_df,snp_df,by=c("year","month"))
final_merged_data <- left_join(Joint_df, unemployment_df, by = c("year","month"))
```

### Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

------------------------------------------------------------------------

# Problem 2

### Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data

### The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

``` r
Mr_Trash_Wheel_df=
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx",sheet="Mr. Trash Wheel",range="A2:N586")|>
  janitor::clean_names()|>
  mutate(homes_powered=weight_tons*500/30)|>
  mutate(wheel_type="Mr")|>
  mutate(year,year=as.numeric(year))
```

### Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.

``` r
Professor_Trash_Wheel_df=
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx",sheet="Professor Trash Wheel",range="A2:M108")|>
  janitor::clean_names()|>
  mutate(homes_powered=weight_tons*500/30)|>
  mutate(wheel_type="Professor")

Gwynnda_Trash_Wheel_df=
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx",sheet="Gwynnda Trash Wheel",range="A2:L157")|>
  janitor::clean_names()|>
  mutate(homes_powered=weight_tons*500/30)|>
  mutate(wheel_type="Gwynnda")
```

``` r
Trash_Wheel_df=
  bind_rows(Mr_Trash_Wheel_df,
            Professor_Trash_Wheel_df,
            Gwynnda_Trash_Wheel_df)|>
  relocate(wheel_type)
```

### Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?

The number of observations in the resulting dataset is 845. There are 15
variables. We can tell from the resulting dataset that from 2014 to 2023
, the number of homes powered by trash recorded by this survey is about
42383.5. The total weight of trash collected by Professor Trash Wheel is
216.26. The the total number of cigarette butts collected by Gwynnda in
July of 2021 is 16300. All of those suggest that this project is
meaningful and it really did a lot in trash collecting and making it
useful to the public.

# Problem 3

### Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).

``` r
baseline_df=read.csv("./data/data_mci/MCI_baseline.csv",skip=1)|>
  janitor::clean_names()|>
  mutate(
    sex=case_match(
      sex,
      0~"Male",
      1~"Female"
    ))|>
  mutate(
    apoe4=case_match(
      apoe4,
      0~"non-carrier",
      1~"APOE4 carrier"
    )
  )|>
  subset(
    age_at_onset>=current_age|age_at_onset=="."
  )
```

### Discuss important steps in the import process and relevant features of the dataset. How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers?

In the import process, I used skip to avoid the non-numeric line. And
used “janitor::clean_names()” to make the colnames clearer to read. And
I recode the sex variable from number to “male” and “female”, change the
apoe4 variable from 0 and 1 to “non-carrier” and “APOE4 carrier”, which
is easier to understand. Finally, since the age at onset is impossible
to be less the the baseline age , I used subset to avoid whose data do
not align with the fact. There are 483 participants recruited, 480 of
these develop MCI. The average baseline age is about 65. The proprtion
of women in the study are APOE4 carriers is 0.3.

### Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.

``` r
mci_amyloid_df=read.csv("./data/data_mci/mci_amyloid.csv",skip=1)|>
  janitor::clean_names()|>
  subset(
   baseline!="NA"& baseline!="Na"
  )|>
  rename(
  id=study_id
  )
```

I firstly import the data and omit non-data entries. Then I remove any
participants who have no MCI at baseline. Finally, to better combine two
datasets, I change the row name “study_id” to “id”, which is the same as
the row name of baseline_df. There are 487 participants recruited, 485
of them have the biomarker at the baseline. The proportion of those
participants who complete the whole process is 0.7134021.

### Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

``` r
left_join_df=
  left_join(baseline_df,mci_amyloid_df,by="id")
only_in_baseline_df=
  left_join_df|>
  subset(
    is.na(left_join_df$baseline))
```

There are three participants appear in only the baseline, there ids are
14, 49, and 268.

``` r
right_join_df=
  right_join(baseline_df,mci_amyloid_df,by="id")
only_in_amyloid_df=
  right_join_df|>
  subset(
    is.na(right_join_df$age_at_onset))
```

There are 14 participants appear in only the amyloid datasets, which
means some basic demographic information were missed out at the study
baseline.

``` r
combine_df=
  inner_join(baseline_df,mci_amyloid_df,by="id")
full_data_df=
  na.omit(combine_df)
long_format_df=
  combine_df|>
  pivot_longer(
    baseline:time_8,
    names_to="time",
    values_to="mci_amyloid"
  )
write.csv(combine_df, "combined_data.csv", row.names = FALSE)
write.csv(full_data_df, "full_data.csv", row.names = FALSE)
write.csv(long_format_df, "long_format_of_combined_data.csv", row.names = FALSE)
```

There 471 participants appear in both datasets, and there are only 335
participants completing the whole follow-up survey.
